# python-test-task
## Запуск в Docker
- Склонируйте репозиторий, загрузите зависимости и создайте `.env` файл из шаблона:

```bash
git clone https://github.com/bleschunov/python_test_task.git
cd python_test_task
pdm sync
cat .env.template >> .env
```

- В `.env` заполните переменные окружения.
  - В `POSTGRES_USER` и `PGUSER` можно поставить одинаковые значения.
  - В `POSTGRES_HOST` нужно поставить postgres [название сервиса в docker-compose.yml], так как далее будет запускать в контейнере.
  - `DATA_FOLDER` — это путь к папке `/path/to/python_test_task/data`.
    - В этой папке находятся XML файлы для обработки и данные для PostgreSQL.
    - Это папка маунтится в контейнеры.
  - `TARGET_FILENAME` – это название XML внутри data для обработки сервисом.

```bash
docker compose up postgres -d
docker compose run service
```

После запуска вы увидите прогресс бар.

> [!Tip]  
> В `/path/to/python_test_task/data` лежит файл `test.xml`, состоящий из 5 `<offer>`. Файл удобно использовать для быстрого теста.

> [!Tip]  
> Важно запускать сервис через команду run, чтобы увидеть прогресс–бар.


## Как запустить сервис для другого файла?
1. Положите ваш файл в `/path/to/python_test_task/data`.
2. Укажите название вашего файла в `.env` в переменной `TARGET_FILENAME`.
3. Запустите сервис.
4. Вы великолепны.


## Как можно в дальнейшем ускорить обработку?
### Задача I/O bound. Это значит, что можно было бы использовать async/await для ускорения работы?
- Про I/O bound — это правда, потому что у нас из тяжёлых операций — это чтение XML и записи в БД. Однако не на всех платформах доступен асинхронный доступ к файловой системе.
- Можно было бы асинхронно скачивать XML чанками, а не читать из файловой системы синхронно. Тогда нужно будет решать проблему «разрыва» тега внутри одного чанка.
### Если нельзя использовать асинхронность, тогда есть многопроцессорность!
- Да, можно использовать несколько процессов.
- В этом решении будет один главный процесс, который будет парсить XML и для каждого тега `<offer>` создавать джобы на выполнение.
- Процессы из пула будут брать эти джобы и выполнять.
- Для экстремально больших файлов уместно будет использовать распределённую очередь, к которой будут обращаться несколько инстансов сервиса.


## Как запустить тесты?

Выполните команду:

```bash
python -m unittest discover
```

## FAQ

### Почему не стал использовать ORM, например SQLAlchemy?
Посчитал, что в решении не будет сложных SQL запросов, так что нет необходимости тащить тяжёлую зависимость. Достаточно ограничиться более низкоуровневой psycopg2.

